#!/usr/bin/env python3
"""
ç”µå•†çˆ¬è™«ä¸»å…¥å£æ–‡ä»¶
å¢å¼ºç‰ˆæœ¬ - åŒ…å«å•†å“é“¾æ¥ã€åº—é“ºåç§°ã€è¯„è®ºæ—¶é—´ç­‰å®Œæ•´å­—æ®µ
"""
import sys
import os
import logging
from datetime import datetime

# è·¯å¾„ä¿®å¤ - ç¡®ä¿èƒ½æ‰¾åˆ°é¡¹ç›®æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

from config import Config
from utils.logger import setup_logger
from utils.database import get_db_manager
from models.product import ProductData
from tests.demo.reference_based_scraper import ReferenceBasedScraper


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç”µå•†çˆ¬è™«ç³»ç»Ÿå¯åŠ¨ - å¢å¼ºç‰ˆæœ¬")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ—¥å¿—
    logger = setup_logger()
    logger.info("çˆ¬è™«ç³»ç»Ÿå¯åŠ¨ - å¢å¼ºç‰ˆæœ¬")
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("ğŸ“‹ ç³»ç»Ÿé…ç½®ä¿¡æ¯:")
    print(f"  ç›®æ ‡ç½‘ç«™: {Config.TARGET_URL}")
    print(f"  æ•°æ®åº“: {Config.MONGO_URI}")
    print(f"  æ•°æ®åº“å: {Config.DATABASE_NAME}")
    print(f"  é›†åˆå: {Config.COLLECTION_NAME}")
    print(f"  æœ€å°å»¶æ—¶: {Config.MIN_DELAY}ç§’")
    print(f"  æœ€å¤§å»¶æ—¶: {Config.MAX_DELAY}ç§’")
    print(f"  æœ€å¤§é‡è¯•: {Config.MAX_RETRY}æ¬¡")
    
    # æ˜¾ç¤ºå¢å¼ºåŠŸèƒ½
    print("\nğŸ” å¢å¼ºå­—æ®µé‡‡é›†åŠŸèƒ½:")
    print("  âœ… å•†å“é“¾æ¥ (product_url)")
    print("  âœ… åº—é“ºåç§° (shop_name)")
    print("  âœ… è¯„è®ºæ—¶é—´ (latest_review_fmt, earliest_review_fmt)")
    print("  âœ… å•†å“å›¾ç‰‡ (product_image)")
    print("  âœ… å•†å“æè¿° (desc_detail)")
    print("  âœ… é”€é‡ä¿¡æ¯ (sold_count)")
    print("  âœ… è¯„åˆ†ä¿¡æ¯ (product_rating)")
    
    # æµ‹è¯•æ•°æ®åº“è¿æ¥
    print("\nğŸ”— æµ‹è¯•æ•°æ®åº“è¿æ¥...")
    db_manager = get_db_manager()
    
    if db_manager.connect():
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        stats = db_manager.get_statistics()
        if "error" not in stats:
            print(f"  å½“å‰æ•°æ®æ€»æ•°: {stats['total_products']}æ¡")
            print(f"  æ»‘å—æˆåŠŸç‡: {stats['slider_success_rate']}%")
        
        db_manager.disconnect()
    else:
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
        logger.error("æ•°æ®åº“è¿æ¥å¤±è´¥")
        return
    
    # æ˜¾ç¤ºé¡¹ç›®ç»“æ„
    print("\nğŸ“ é¡¹ç›®ç»“æ„:")
    print("  crawler-project/")
    print("  â”œâ”€â”€ main.py              # ä¸»å…¥å£æ–‡ä»¶")
    print("  â”œâ”€â”€ config.py            # é…ç½®ç®¡ç†")
    print("  â”œâ”€â”€ models/              # æ•°æ®æ¨¡å‹")
    print("  â”‚   â”œâ”€â”€ __init__.py")
    print("  â”‚   â””â”€â”€ product.py       # å•†å“æ•°æ®æ¨¡å‹ (å¢å¼ºç‰ˆ)")
    print("  â”œâ”€â”€ utils/               # å·¥å…·ç±»")
    print("  â”‚   â”œâ”€â”€ __init__.py")
    print("  â”‚   â”œâ”€â”€ database.py      # æ•°æ®åº“æ“ä½œ")
    print("  â”‚   â””â”€â”€ logger.py        # æ—¥å¿—å·¥å…·")
    print("  â”œâ”€â”€ handlers/            # å¤„ç†å™¨")
    print("  â”‚   â”œâ”€â”€ __init__.py")
    print("  â”‚   â”œâ”€â”€ slider.py        # æ»‘å—å¤„ç†")
    print("  â”‚   â””â”€â”€ extractor.py     # æ•°æ®æå–")
    print("  â”œâ”€â”€ tests/               # æµ‹è¯•ä»£ç ")
    print("  â”‚   â”œâ”€â”€ unit/           # å•å…ƒæµ‹è¯•")
    print("  â”‚   â”œâ”€â”€ integration/    # é›†æˆæµ‹è¯•")
    print("  â”‚   â””â”€â”€ demo/           # æ¼”ç¤ºä»£ç ")
    print("  â”œâ”€â”€ requirements.txt     # ä¾èµ–åŒ…")
    print("  â””â”€â”€ logs/               # æ—¥å¿—ç›®å½•")
    
    print("\nâœ… å¢å¼ºæ¡†æ¶åˆå§‹åŒ–å®Œæˆ")
    logger.info("å¢å¼ºæ¡†æ¶åˆå§‹åŒ–å®Œæˆ")
    
    # æ¼”ç¤ºå¢å¼ºåŠŸèƒ½
    print("\nğŸ¯ æ¼”ç¤ºå¢å¼ºå­—æ®µé‡‡é›†åŠŸèƒ½:")
    print("  è¿è¡Œç¤ºä¾‹: python tests/demo/reference_based_scraper.py")
    print("  éªŒè¯å­—æ®µ: python test_enhanced_fields_simple.py")
    print("  æ£€æŸ¥æ•°æ®: python check_product_fields.py")
    
    print("\nğŸ“ ä¸‹ä¸€æ­¥:")
    print("  1. è¿è¡Œå¢å¼ºå­—æ®µé‡‡é›†æµ‹è¯•")
    print("  2. éªŒè¯æ‰€æœ‰å­—æ®µå®Œæ•´æ€§")
    print("  3. é›†æˆåˆ°ç”Ÿäº§ç¯å¢ƒ")
    print("  4. ä¼˜åŒ–æ€§èƒ½å’Œç¨³å®šæ€§")


def run_enhanced_scraping_demo():
    """è¿è¡Œå¢å¼ºå­—æ®µé‡‡é›†æ¼”ç¤º"""
    print("\nğŸ¯ è¿è¡Œå¢å¼ºå­—æ®µé‡‡é›†æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–é‡‡é›†å™¨
        scraper = ReferenceBasedScraper()
        print("âœ… é‡‡é›†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æ‰§è¡Œé‡‡é›†
        keyword = "phone case"
        page_count = 1
        print(f"ğŸ“¦ å¼€å§‹é‡‡é›†å•†å“æ•°æ® (å…³é”®è¯: {keyword}, é¡µæ•°: {page_count})")
        
        products = scraper.scrape_keyword_products(keyword, page_count)
        print(f"ğŸ‰ é‡‡é›†å®Œæˆï¼Œå…±è·å– {len(products)} ä¸ªå•†å“")
        
        # æ˜¾ç¤ºæ ·æœ¬æ•°æ®
        if products:
            print("\nğŸ“Š æ ·æœ¬å•†å“æ•°æ®:")
            sample_product = products[0]
            print(f"  å•†å“ID: {sample_product.get('product_id')}")
            print(f"  å•†å“æ ‡é¢˜: {sample_product.get('title', '')[:50]}...")
            print(f"  å•†å“ä»·æ ¼: ${sample_product.get('current_price')}")
            print(f"  å•†å“é“¾æ¥: {sample_product.get('product_url')}")
            print(f"  åº—é“ºåç§°: {sample_product.get('shop_name')}")
            print(f"  æœ€è¿‘è¯„ä»·æ—¶é—´: {sample_product.get('latest_review_fmt') or 'æš‚æ— '}")
            print(f"  æœ€æ—©è¯„ä»·æ—¶é—´: {sample_product.get('earliest_review_fmt') or 'æš‚æ— '}")
        
        scraper.close()
        print("\nâœ… å¢å¼ºå­—æ®µé‡‡é›†æ¼”ç¤ºå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
    
    # å¯é€‰ï¼šè¿è¡Œæ¼”ç¤º
    # run_enhanced_scraping_demo()