#!/usr/bin/env python3
"""
Crawlabç”µå•†çˆ¬è™«è„šæœ¬
é›†æˆåˆ°Crawlabå¹³å°çš„ä¸»è¦çˆ¬è™«è„šæœ¬
"""
import os
import sys
import json
import time
import argparse
from datetime import datetime
from typing import List, Dict, Any

# è·¯å¾„ä¿®å¤ - ç¡®ä¿èƒ½æ‰¾åˆ°é¡¹ç›®æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

from config import Config
from utils.logger import setup_logger, get_logger
from utils.webdriver import WebDriverManager
from handlers.extractor import DataExtractor
from handlers.slider import SliderHandler
from models.product import ProductData
from utils.database import get_db_manager


class CrawlabSpider:
    """Crawlabç”µå•†çˆ¬è™«ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.logger = setup_logger('crawlab_spider')
        self.webdriver_manager = None
        self.db_manager = get_db_manager()
        self.stats = {
            'total_keywords': 0,
            'total_products': 0,
            'successful_keywords': 0,
            'failed_keywords': 0,
            'slider_encountered': 0,
            'slider_solved': 0,
            'start_time': None,
            'end_time': None
        }
        
        self.logger.info("Crawlabç”µå•†çˆ¬è™«åˆå§‹åŒ–å®Œæˆ")
    
    def parse_arguments(self):
        """è§£æå‘½ä»¤è¡Œå‚æ•°"""
        parser = argparse.ArgumentParser(description='Crawlabç”µå•†çˆ¬è™«')
        parser.add_argument('--keywords', type=str, help='æœç´¢å…³é”®è¯ï¼Œå¤šä¸ªå…³é”®è¯ç”¨é€—å·åˆ†éš”')
        parser.add_argument('--max-pages', type=int, default=1, help='æ¯ä¸ªå…³é”®è¯æœ€å¤§é‡‡é›†é¡µæ•°')
        parser.add_argument('--headless', action='store_true', help='ä½¿ç”¨æ— å¤´æ¨¡å¼')
        parser.add_argument('--output', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
        
        args = parser.parse_args()
        
        # å¦‚æœæ²¡æœ‰æä¾›å…³é”®è¯ï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        if not args.keywords:
            args.keywords = os.getenv('CRAWLAB_KEYWORDS', 'phone case,wireless charger')
        
        return args
    
    def setup_crawlab_environment(self):
        """è®¾ç½®Crawlabç¯å¢ƒ"""
        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨Crawlabç¯å¢ƒä¸­è¿è¡Œ
            crawlab_task_id = os.getenv('CRAWLAB_TASK_ID')
            crawlab_node_id = os.getenv('CRAWLAB_NODE_ID')
            
            if crawlab_task_id:
                self.logger.info(f"è¿è¡Œåœ¨Crawlabç¯å¢ƒä¸­")
                self.logger.info(f"ä»»åŠ¡ID: {crawlab_task_id}")
                self.logger.info(f"èŠ‚ç‚¹ID: {crawlab_node_id}")
                
                # è®¾ç½®Crawlabç‰¹å®šçš„é…ç½®
                self.is_crawlab_env = True
            else:
                self.logger.info("è¿è¡Œåœ¨æœ¬åœ°ç¯å¢ƒä¸­")
                self.is_crawlab_env = False
                
        except Exception as e:
            self.logger.error(f"è®¾ç½®Crawlabç¯å¢ƒå¤±è´¥: {e}")
            self.is_crawlab_env = False
    
    def crawl_keyword(self, keyword: str, max_pages: int = 1) -> List[ProductData]:
        """çˆ¬å–å•ä¸ªå…³é”®è¯çš„å•†å“æ•°æ®"""
        products = []
        
        try:
            self.logger.info(f"å¼€å§‹çˆ¬å–å…³é”®è¯: {keyword}")
            
            # åˆ›å»ºWebDriver
            if not self.webdriver_manager:
                self.webdriver_manager = WebDriverManager(headless=True)
                driver = self.webdriver_manager.create_driver()
                
                if not driver:
                    raise Exception("WebDriveråˆ›å»ºå¤±è´¥")
            
            # æœç´¢å…³é”®è¯
            if self.webdriver_manager.search_products(keyword):
                self.logger.info(f"æˆåŠŸæœç´¢å…³é”®è¯: {keyword}")
                
                # æ£€æµ‹å’Œå¤„ç†æ»‘å—
                slider_handler = SliderHandler(self.webdriver_manager.get_driver())
                
                if slider_handler.detect_slider():
                    self.stats['slider_encountered'] += 1
                    self.logger.warning("æ£€æµ‹åˆ°æ»‘å—éªŒè¯")
                    
                    if slider_handler.handle_captcha_with_retry():
                        self.stats['slider_solved'] += 1
                        self.logger.info("æ»‘å—éªŒè¯å¤„ç†æˆåŠŸ")
                    else:
                        self.logger.error("æ»‘å—éªŒè¯å¤„ç†å¤±è´¥ï¼Œè·³è¿‡æ­¤å…³é”®è¯")
                        self.stats['failed_keywords'] += 1
                        return products
                
                # æå–å•†å“æ•°æ®
                for page_num in range(1, max_pages + 1):
                    self.logger.info(f"æå–ç¬¬ {page_num} é¡µæ•°æ®")
                    
                    page_products_data = self.webdriver_manager.extract_products_from_page(keyword, page_num)
                    
                    for product_data in page_products_data:
                        try:
                            product = ProductData(
                                keyword=keyword,
                                title=product_data.get('title', ''),
                                scraped_at=datetime.now(),
                                slider_encountered=self.stats['slider_encountered'] > 0,
                                slider_solved=self.stats['slider_solved'] > 0
                            )
                            products.append(product)
                        except Exception as e:
                            self.logger.warning(f"åˆ›å»ºå•†å“å¯¹è±¡å¤±è´¥: {e}")
                    
                    # ç¿»é¡µå»¶æ—¶
                    if page_num < max_pages:
                        time.sleep(2)
                
                self.stats['successful_keywords'] += 1
                self.logger.info(f"å…³é”®è¯ '{keyword}' çˆ¬å–å®Œæˆï¼Œè·å¾— {len(products)} ä¸ªå•†å“")
                
            else:
                self.logger.error(f"æœç´¢å…³é”®è¯ '{keyword}' å¤±è´¥")
                self.stats['failed_keywords'] += 1
                
        except Exception as e:
            self.logger.error(f"çˆ¬å–å…³é”®è¯ '{keyword}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            self.stats['failed_keywords'] += 1
        
        return products
    
    def save_products_to_database(self, products: List[ProductData]) -> int:
        """ä¿å­˜å•†å“æ•°æ®åˆ°æ•°æ®åº“"""
        saved_count = 0
        
        try:
            if self.db_manager.connect():
                for product in products:
                    if self.db_manager.insert_product(product):
                        saved_count += 1
                        
                        # åœ¨Crawlabç¯å¢ƒä¸­è¾“å‡ºç»“æœ
                        if self.is_crawlab_env:
                            # Crawlabä¼šè‡ªåŠ¨æ”¶é›†è¿™ç§æ ¼å¼çš„è¾“å‡º
                            result_data = {
                                'keyword': product.keyword,
                                'title': product.title,
                                'scraped_at': product.scraped_at.isoformat(),
                                'slider_encountered': product.slider_encountered,
                                'slider_solved': product.slider_solved
                            }
                            print(json.dumps(result_data, ensure_ascii=False))
                
                self.db_manager.disconnect()
                self.logger.info(f"æˆåŠŸä¿å­˜ {saved_count} ä¸ªå•†å“åˆ°æ•°æ®åº“")
            else:
                self.logger.error("æ•°æ®åº“è¿æ¥å¤±è´¥")
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        
        return saved_count
    
    def save_products_to_file(self, products: List[ProductData], output_file: str):
        """ä¿å­˜å•†å“æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            products_data = []
            for product in products:
                products_data.append({
                    'keyword': product.keyword,
                    'title': product.title,
                    'scraped_at': product.scraped_at.isoformat(),
                    'slider_encountered': product.slider_encountered,
                    'slider_solved': product.slider_solved
                })
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(products_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"å•†å“æ•°æ®å·²ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶å¤±è´¥: {e}")
    
    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats['end_time'] = datetime.now()
        
        if self.stats['start_time']:
            duration = self.stats['end_time'] - self.stats['start_time']
            duration_str = str(duration).split('.')[0]  # å»æ‰å¾®ç§’
        else:
            duration_str = "æœªçŸ¥"
        
        print("\n" + "=" * 60)
        print("ğŸ“Š çˆ¬å–ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 60)
        print(f"æ€»å…³é”®è¯æ•°: {self.stats['total_keywords']}")
        print(f"æˆåŠŸå…³é”®è¯: {self.stats['successful_keywords']}")
        print(f"å¤±è´¥å…³é”®è¯: {self.stats['failed_keywords']}")
        print(f"æ€»å•†å“æ•°: {self.stats['total_products']}")
        print(f"é‡åˆ°æ»‘å—: {self.stats['slider_encountered']} æ¬¡")
        print(f"æ»‘å—æˆåŠŸ: {self.stats['slider_solved']} æ¬¡")
        
        if self.stats['slider_encountered'] > 0:
            success_rate = (self.stats['slider_solved'] / self.stats['slider_encountered']) * 100
            print(f"æ»‘å—æˆåŠŸç‡: {success_rate:.1f}%")
        
        print(f"æ‰§è¡Œæ—¶é—´: {duration_str}")
        print("=" * 60)
        
        # è®°å½•åˆ°æ—¥å¿—
        self.logger.info(f"çˆ¬å–å®Œæˆç»Ÿè®¡: å…³é”®è¯{self.stats['successful_keywords']}/{self.stats['total_keywords']}, "
                        f"å•†å“{self.stats['total_products']}ä¸ª, è€—æ—¶{duration_str}")
    
    def run(self):
        """è¿è¡Œçˆ¬è™«"""
        try:
            self.stats['start_time'] = datetime.now()
            
            # è§£æå‚æ•°
            args = self.parse_arguments()
            
            # è®¾ç½®Crawlabç¯å¢ƒ
            self.setup_crawlab_environment()
            
            # è§£æå…³é”®è¯
            keywords = [kw.strip() for kw in args.keywords.split(',') if kw.strip()]
            self.stats['total_keywords'] = len(keywords)
            
            self.logger.info(f"å¼€å§‹çˆ¬å–ä»»åŠ¡ï¼Œå…³é”®è¯: {keywords}")
            self.logger.info(f"æœ€å¤§é¡µæ•°: {args.max_pages}")
            self.logger.info(f"æ— å¤´æ¨¡å¼: {args.headless}")
            
            all_products = []
            
            # é€ä¸ªå¤„ç†å…³é”®è¯
            for i, keyword in enumerate(keywords, 1):
                self.logger.info(f"å¤„ç†å…³é”®è¯ {i}/{len(keywords)}: {keyword}")
                
                products = self.crawl_keyword(keyword, args.max_pages)
                all_products.extend(products)
                
                # å…³é”®è¯é—´å»¶æ—¶
                if i < len(keywords):
                    delay = 3
                    self.logger.info(f"å…³é”®è¯é—´å»¶æ—¶ {delay} ç§’...")
                    time.sleep(delay)
            
            self.stats['total_products'] = len(all_products)
            
            # ä¿å­˜æ•°æ®
            if all_products:
                # ä¿å­˜åˆ°æ•°æ®åº“
                saved_count = self.save_products_to_database(all_products)
                self.logger.info(f"æ•°æ®åº“ä¿å­˜: {saved_count}/{len(all_products)}")
                
                # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶ï¼‰
                if args.output:
                    self.save_products_to_file(all_products, args.output)
            
            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            self.print_statistics()
            
            self.logger.info("çˆ¬å–ä»»åŠ¡å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"çˆ¬å–ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            raise
        
        finally:
            # æ¸…ç†èµ„æº
            if self.webdriver_manager:
                self.webdriver_manager.close_driver()
                self.logger.info("WebDriverèµ„æºå·²æ¸…ç†")


def main():
    """ä¸»å‡½æ•°"""
    try:
        spider = CrawlabSpider()
        spider.run()
        
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­çˆ¬å–ä»»åŠ¡")
        
    except Exception as e:
        print(f"çˆ¬å–ä»»åŠ¡å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()