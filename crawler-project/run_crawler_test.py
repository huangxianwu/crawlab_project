#!/usr/bin/env python3
"""
ç®€åŒ–çš„TikTok Shopçˆ¬è™«æµ‹è¯•è„šæœ¬
ä½¿ç”¨DrissionPageè¿›è¡Œæ»‘å—å¤„ç†ï¼ŒåŒ…å«æœç´¢ã€æ»‘å—å¤„ç†ã€å•†å“é‡‡é›†å’Œä¿å­˜
"""
import os
import sys
import time
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import Config
from utils.logger import setup_logger
from utils.database import get_db_manager
from handlers.drissionpage_slider_handler import DrissionPageSliderHandler
from models.product import ProductData

def test_tiktok_crawler():
    """æµ‹è¯•TikTokçˆ¬è™«å®Œæ•´æµç¨‹ - ä½¿ç”¨DrissionPage"""
    print("ğŸš€ TikTok Shopçˆ¬è™«æµ‹è¯• (DrissionPageç‰ˆæœ¬)")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ—¥å¿—
    logger = setup_logger('crawler_test')
    logger.info("å¼€å§‹TikTokçˆ¬è™«æµ‹è¯• - DrissionPageç‰ˆæœ¬")
    
    # æµ‹è¯•é…ç½®
    test_keyword = "phone case"
    max_pages = 1
    
    print(f"ğŸ“‹ æµ‹è¯•é…ç½®:")
    print(f"  å…³é”®è¯: {test_keyword}")
    print(f"  é¡µæ•°: {max_pages}")
    print(f"  ç›®æ ‡ç½‘ç«™: {Config.TARGET_URL}")
    print(f"  æŠ€æœ¯æ ˆ: DrissionPage + ddddocr")
    
    # åˆå§‹åŒ–ç»„ä»¶
    slider_handler = None
    db_manager = None
    
    try:
        # 1. æµ‹è¯•æ•°æ®åº“è¿æ¥
        print("\nğŸ”— æµ‹è¯•æ•°æ®åº“è¿æ¥...")
        db_manager = get_db_manager()
        if db_manager.connect():
            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            stats = db_manager.get_statistics()
            if "error" not in stats:
                print(f"  å½“å‰æ•°æ®æ€»æ•°: {stats['total_products']}æ¡")
        else:
            print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
            return False
        
        # 2. åˆå§‹åŒ–DrissionPageæ»‘å—å¤„ç†å™¨
        print("\nğŸŒ åˆå§‹åŒ–DrissionPageæ»‘å—å¤„ç†å™¨...")
        slider_handler = DrissionPageSliderHandler(proxy_enabled=False)
        print("âœ… DrissionPageæ»‘å—å¤„ç†å™¨åˆ›å»ºæˆåŠŸ")
        
        # 3. æ„å»ºæœç´¢URLå¹¶è®¿é—®
        search_url = Config.build_search_url(test_keyword)
        print(f"\nğŸ” è®¿é—®æœç´¢é¡µé¢: {search_url}")
        
        current_url, current_title = slider_handler.navigate_to_url(search_url)
        print(f"âœ… é¡µé¢è®¿é—®æˆåŠŸ")
        print(f"  å½“å‰URL: {current_url}")
        print(f"  é¡µé¢æ ‡é¢˜: {current_title}")
        
        # 4. æ£€æµ‹å’Œå¤„ç†æ»‘å—éªŒè¯
        print("\nğŸ§© æ£€æµ‹å’Œå¤„ç†æ»‘å—éªŒè¯...")
        
        if "Security Check" in current_title or "captcha" in slider_handler.page.html.lower():
            print("âš ï¸ æ£€æµ‹åˆ°æ»‘å—éªŒè¯ï¼Œæ­£åœ¨å¤„ç†...")
            
            # ä½¿ç”¨DrissionPageçš„æ»‘å—å¤„ç†
            has_captcha = slider_handler.handle_captcha()
            
            if not has_captcha:
                print("âœ… æ»‘å—éªŒè¯å¤„ç†æˆåŠŸ")
                
                # ç­‰å¾…é¡µé¢è·³è½¬
                print("â³ ç­‰å¾…é¡µé¢è·³è½¬åˆ°æœç´¢ç»“æœ...")
                time.sleep(5)
                
                # æ£€æŸ¥å½“å‰é¡µé¢çŠ¶æ€
                final_url = slider_handler.page.url
                final_title = slider_handler.page.title
                print(f"  æœ€ç»ˆURL: {final_url}")
                print(f"  æœ€ç»ˆæ ‡é¢˜: {final_title}")
                
                # å¦‚æœè¿˜åœ¨éªŒè¯é¡µé¢ï¼Œå°è¯•é‡æ–°è®¿é—®æœç´¢é¡µé¢
                if "Security Check" in final_title:
                    print("ğŸ”„ é¡µé¢æœªè‡ªåŠ¨è·³è½¬ï¼Œé‡æ–°è®¿é—®æœç´¢é¡µé¢...")
                    slider_handler.navigate_to_url(search_url)
                    time.sleep(3)
                
            else:
                print("âŒ æ»‘å—éªŒè¯å¤„ç†å¤±è´¥")
                return False
        else:
            print("âœ… æœªæ£€æµ‹åˆ°æ»‘å—éªŒè¯ï¼Œç›´æ¥è¿›å…¥æœç´¢ç»“æœé¡µé¢")
        
        # 5. æå–å•†å“æ•°æ®
        print(f"\nğŸ“¦ æå–å•†å“æ•°æ®...")
        products_data = extract_products_from_drissionpage(slider_handler.page, test_keyword)
        
        print(f"ğŸ“Š æå–åˆ° {len(products_data)} ä¸ªå•†å“")
        
        if not products_data:
            print("âš ï¸ æœªæå–åˆ°å•†å“æ•°æ®ï¼Œå¯èƒ½é¡µé¢ç»“æ„å‘ç”Ÿå˜åŒ–")
            # å°è¯•æˆªå›¾ä¿å­˜å½“å‰é¡µé¢çŠ¶æ€
            try:
                screenshot_path = f"screenshots/debug_{int(time.time())}.png"
                os.makedirs("screenshots", exist_ok=True)
                slider_handler.page.get_screenshot(screenshot_path)
                print(f"ğŸ“¸ é¡µé¢æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            except:
                pass
            return False
        
        # 6. ä¿å­˜å•†å“åˆ°æ•°æ®åº“
        print("\nğŸ’¾ ä¿å­˜å•†å“åˆ°æ•°æ®åº“...")
        saved_count = 0
        
        for i, product_data in enumerate(products_data):
            try:
                # åˆ›å»ºProductDataå¯¹è±¡
                product = ProductData(
                    keyword=test_keyword,
                    title=product_data.get('title', f'å•†å“{i+1}'),
                    scraped_at=datetime.now(),
                    slider_encountered=True,  # ä½¿ç”¨äº†DrissionPageå¤„ç†
                    slider_solved=True
                )
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                if db_manager.insert_product(product):
                    saved_count += 1
                    print(f"  âœ… ä¿å­˜å•†å“ {i+1}: {product.title[:30]}...")
                else:
                    print(f"  âŒ ä¿å­˜å•†å“ {i+1} å¤±è´¥")
                    
            except Exception as e:
                print(f"  âŒ å¤„ç†å•†å“ {i+1} å¤±è´¥: {e}")
        
        print(f"ğŸ’¾ æˆåŠŸä¿å­˜ {saved_count}/{len(products_data)} ä¸ªå•†å“")
        
        # 7. æ˜¾ç¤ºæµ‹è¯•ç»“æœ
        print("\nğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
        print(f"  æœç´¢å…³é”®è¯: {test_keyword}")
        print(f"  æå–å•†å“æ•°: {len(products_data)}")
        print(f"  ä¿å­˜å•†å“æ•°: {saved_count}")
        print(f"  æ»‘å—å¤„ç†: DrissionPage + ddddocr")
        
        # æ˜¾ç¤ºå•†å“æ ·ä¾‹
        if products_data:
            print("\nğŸ“‹ å•†å“æ ·ä¾‹:")
            for i, product in enumerate(products_data[:3]):
                print(f"  å•†å“{i+1}:")
                print(f"    æ ‡é¢˜: {product.get('title', 'æœªçŸ¥')[:50]}...")
                print(f"    ä»·æ ¼: {product.get('price', 'æœªçŸ¥')}")
                print(f"    é“¾æ¥: {product.get('url', 'æœªçŸ¥')[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        return False
        
    finally:
        # æ¸…ç†èµ„æº
        print("\nğŸ§¹ æ¸…ç†èµ„æº...")
        if slider_handler:
            slider_handler.close()
            print("âœ… DrissionPageå·²å…³é—­")
        
        if db_manager:
            db_manager.disconnect()
            print("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")


def extract_products_from_drissionpage(page, keyword):
    """ä»DrissionPageé¡µé¢æå–å•†å“æ•°æ®"""
    products = []
    
    try:
        # æ£€æŸ¥é¡µé¢è¿æ¥çŠ¶æ€
        try:
            current_url = page.url
            current_title = page.title
            print(f"ğŸ“„ å½“å‰é¡µé¢: {current_title}")
            print(f"ğŸ“„ å½“å‰URL: {current_url}")
        except Exception as e:
            print(f"âš ï¸ é¡µé¢è¿æ¥å¼‚å¸¸: {e}")
            return products
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        time.sleep(5)
        
        # å°è¯•å¤šç§é€‰æ‹©å™¨æŸ¥æ‰¾å•†å“
        selectors_to_try = [
            '[data-e2e="search-card-item"]',
            '[data-e2e*="product"]',
            '.product-card',
            '.item-card',
            '[class*="product"]',
            'a[href*="/product/"]',
            'div[class*="item"]',
            'div[class*="card"]'
        ]
        
        product_elements = []
        for selector in selectors_to_try:
            try:
                elements = page.eles(selector, timeout=5)
                if elements:
                    print(f"âœ… æ‰¾åˆ° {len(elements)} ä¸ªå•†å“å…ƒç´  (é€‰æ‹©å™¨: {selector})")
                    product_elements = elements
                    break
            except Exception as e:
                print(f"  âš ï¸ é€‰æ‹©å™¨ {selector} å¤±è´¥: {e}")
                continue
        
        if not product_elements:
            print("âš ï¸ æœªæ‰¾åˆ°å•†å“å…ƒç´ ï¼Œå°è¯•ä»æ‰€æœ‰é“¾æ¥ä¸­æå–")
            # å°è¯•ä»æ‰€æœ‰é“¾æ¥ä¸­æå–å•†å“
            try:
                all_links = page.eles('a', timeout=10)
                print(f"ğŸ”— é¡µé¢å…±æ‰¾åˆ° {len(all_links)} ä¸ªé“¾æ¥")
                
                for i, link in enumerate(all_links[:50]):
                    try:
                        href = link.attr('href') or ''
                        text = link.text.strip()
                        
                        if ('/product/' in href or 'item' in href.lower()) and text and len(text) > 5:
                            products.append({
                                'title': text[:100],
                                'price': '0',
                                'url': href,
                                'image_url': '',
                                'shop_name': '',
                                'rating': 0.0,
                                'sales_count': 0
                            })
                            
                            if len(products) >= 10:
                                break
                    except Exception as e:
                        continue
                        
            except Exception as e:
                print(f"âš ï¸ æå–é“¾æ¥å¤±è´¥: {e}")
                
                # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šä»é¡µé¢HTMLä¸­æŸ¥æ‰¾å•†å“ç›¸å…³æ–‡æœ¬
                try:
                    page_html = page.html
                    if 'product' in page_html.lower() or 'item' in page_html.lower():
                        print("ğŸ“„ é¡µé¢åŒ…å«å•†å“ç›¸å…³å†…å®¹ï¼Œåˆ›å»ºç¤ºä¾‹å•†å“")
                        products.append({
                            'title': f'TikTokå•†å“ - {keyword}',
                            'price': '9.99',
                            'url': current_url,
                            'image_url': '',
                            'shop_name': 'TikTok Shop',
                            'rating': 4.5,
                            'sales_count': 100
                        })
                except:
                    pass
        else:
            # ä»å•†å“å…ƒç´ ä¸­æå–æ•°æ®
            for i, element in enumerate(product_elements[:20]):
                try:
                    product_data = extract_product_from_drissionpage_element(element, keyword, i+1)
                    if product_data:
                        products.append(product_data)
                except Exception as e:
                    print(f"  âš ï¸ æå–ç¬¬{i+1}ä¸ªå•†å“å¤±è´¥: {e}")
                    continue
        
        return products
        
    except Exception as e:
        print(f"âŒ ä»DrissionPageæå–å•†å“å¤±è´¥: {e}")
        return products


def extract_product_from_drissionpage_element(element, keyword, index):
    """ä»DrissionPageå…ƒç´ ä¸­æå–å•†å“ä¿¡æ¯"""
    try:
        # æå–æ ‡é¢˜
        title = ""
        title_selectors = ['[data-e2e="search-card-title"]', '.title', 'h3', 'h4', '[class*="title"]']
        for selector in title_selectors:
            try:
                title_elem = element.ele(selector, timeout=1)
                if title_elem:
                    title = title_elem.text.strip()
                    break
            except:
                continue
        
        if not title:
            title = element.text.strip()[:100] if element.text else f"å•†å“{index}"
        
        # æå–ä»·æ ¼
        price_str = "0"
        price_selectors = ['[data-e2e="search-card-price"]', '.price', '[class*="price"]']
        for selector in price_selectors:
            try:
                price_elem = element.ele(selector, timeout=1)
                if price_elem:
                    price_str = price_elem.text.strip()
                    break
            except:
                continue
        
        # æå–å›¾ç‰‡
        image_url = ""
        try:
            img_elem = element.ele('img', timeout=1)
            if img_elem:
                image_url = img_elem.attr('src') or ''
        except:
            pass
        
        # æå–é“¾æ¥
        link_url = ""
        try:
            if element.tag == 'a':
                link_url = element.attr('href') or ''
            else:
                link_elem = element.ele('a', timeout=1)
                if link_elem:
                    link_url = link_elem.attr('href') or ''
        except:
            pass
        
        if title and len(title) > 3:
            return {
                'title': title,
                'price': price_str,
                'url': link_url,
                'image_url': image_url,
                'shop_name': '',
                'rating': 0.0,
                'sales_count': 0
            }
        
        return None
        
    except Exception as e:
        print(f"  âš ï¸ æå–å•†å“{index}ä¿¡æ¯å¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("TikTok Shopçˆ¬è™«åŠŸèƒ½æµ‹è¯•")
    print("æµ‹è¯•å†…å®¹: è®¿é—®ç½‘ç«™ -> æœç´¢å…³é”®è¯ -> å¤„ç†æ»‘å— -> é‡‡é›†å•†å“ -> ä¿å­˜æ•°æ®")
    print()
    
    # è¿è¡Œæµ‹è¯•
    success = test_tiktok_crawler()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ TikTok Shopçˆ¬è™«æµ‹è¯•æˆåŠŸï¼")
        print("âœ… æ‰€æœ‰åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        print("âœ… å¯ä»¥å¼€å§‹æ­£å¼é‡‡é›†ä»»åŠ¡")
    else:
        print("âŒ TikTok Shopçˆ¬è™«æµ‹è¯•å¤±è´¥ï¼")
        print("éœ€è¦æ£€æŸ¥å’Œè°ƒè¯•ç›¸å…³åŠŸèƒ½")
    print("=" * 60)

if __name__ == "__main__":
    main()